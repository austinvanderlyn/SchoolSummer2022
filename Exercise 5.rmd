---
title: "Exercise 5"
author: "Austin Vanderlyn ajl745"
date: "7/24/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 5

#### This question should be answered using the Weekly data set, which is part of the ISLR package. This data is similar in nature to the Smarket data from this chapter's lab, except that it contains 1,089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010.

Libraries;
```{r}
library(AppliedPredictiveModeling)
library(caret)
library(ISLR)
library(corrplot)
```

Data;
```{r}
data("Weekly")
```



### 5.a

#### Produce some numerical and graphical summaries of the Weekly data. Do there appear to be any patterns? 

Data exploration;
```{r}
head(Weekly)
```

```{r}
plot(Weekly$Volume,
     col = Weekly$Year)
```

Check correlation;
```{r}
wkcor = cor(Weekly[,1:8])
corrplot(wkcor)
```

The only variables that appear to have any significant correlation are Year and Volume, but this isn't really surprising since we're dealing with stock market prices. The stock values don't restart at 0 in a near year, they build off of where the stocks finished at the end of the previous year, so we would expect them to be correlated.


### 5.b

#### Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?

Fit a logistic regression model;
```{r}
set.seed(123)
glmGrid = trainControl(method = "repeatedcv",
                       repeats = 5)

glmTune = train(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
                data = Weekly,
                family = "binomial",
                method = "glm",
                trControl = glmGrid)

summary(glmTune)
```

The only predictor that appears to be significant at the default of alpha = 0.05 is Lag 2, with a p-value of 0.0296.


### 5.c

#### Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression.

Compute confusion matrix;
```{r}
set.seed(123)
preds = predict(glmTune, Weekly)

confusionMatrix(preds, Weekly$Direction)
```


Wow, not the greatest accuracy rate, only 56.11%.

As for the types of errors made, the model is extremely lopsided. Down and Up are a little different from a usual binary predictor 0/1 but if we take down to be 0 and Up to be 1, then the model is way worse when it comes to Type I errors; that is, it predicts Up and actually is Down, a false positive. 

There are 478 misclassifications, and 430 of them are Type I errors, 90% of the total errors. Type II (false negative) are only 10% of the errors.


### 5.d

#### Now fit the logistic regression model using a training data period from 1990 to 2008. Compute the confusion matrix and the overall fraction of correct predictions for the held out data.

create the training and testing set;
```{r}
train = (Weekly$Year <2009)
weeklyTrain = Weekly[train,]
weeklyTest = Weekly[!train,]
```


fit logit model using training data;
```{r}
set.seed(123)
glmGrid = trainControl(method = "repeatedcv",
                       repeats = 5)

glmTune2 = train(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
                data = weeklyTrain,
                family = "binomial",
                method = "glm",
                trControl = glmGrid)

summary(glmTune2)
```


Compute confusion matrix;
```{r}
set.seed(123)
preds2 = predict(glmTune2, weeklyTest)

confusionMatrix(preds2, weeklyTest$Direction)
```


The accuracy of the model actually went down predicting on the test set, though the types of errors are a little bit more balanced out. The overall number of correct predictions on the held out data is 46.15%.


### 5.d

#### Repeat (d) using LDA






















