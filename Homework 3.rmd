---
title: "Homework 3"
author: "Austin Vanderlyn ajl745"
date: "8/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Homework 3

#### 12.2. In Exercise 4.4, we described a data set which contained 96 oil samples each from one of seven types of oils (pumpkin, sunflower, peanut, olive, soybean, rapeseed, and corn). Gas chromatography was performed on each sample and the percentage of each type of 7 fatty acids was determined. We would like to use these data to build a model that predicts the type of oil based on a sample’s fatty acid percentages.


### (a) Like the hepatic injury data, these data suffer from extreme imbalance. Given this imbalance, should the data be split into training and test sets?

To be honest I'm not 100% sure what the question means by extreme imbalance (not normal distribution?) so I want to take a closer look at it first.

Libraries;
```{r}
library(AppliedPredictiveModeling)
library(caret)
library(ISLR)
library(pROC)
library(MASS)
library(glmnet)
library(MLmetrics)
data(oil)
```


plots
```{r}
plot(oilType)
```

Yes, that is definitely not a normal distribution. I don't think that splitting into train and test would necessarily be appropriate here, because the number of observations is so small, and the outcome variable has seven different levels. 


### (b) Which classification statistic would you choose to optimize for this exercise and why?

Well, with a continuous response variable, accuracy is not generally the best metric, but since this is a classification problem, accuracy is a decent enough metric to use.

### (c) Of the models presented in this chapter, which performs best on these data? Which oil type does the model most accurately predict? Least accurately predict?

The models presented in this chapter are; logistic regression, linear discriminant analysis, partial least squares discriminant analysis, penalized models, and nearest shrunken centroids, so those are the various types of models that I will to test this out on, except for logistic regression. That won't really work because this is a seven-level categorical response variable, not a binary one.


Create ctrl function;
```{r}
set.seed(123)
ctrl = trainControl(method = "LGOCV",
                    classProbs = TRUE,
                    savePredictions = TRUE)
```


Fit least discriminant analysis regression model;
```{r}
set.seed(123)
ldaTune = train(fattyAcids, oilType,
                method = "lda",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl)
ldaTune
```


LDA predictions;
```{r}
testResults = data.frame(obs = oilType,
                         lda = predict(ldaTune, fattyAcids))
testResults
```



Fit PLSDA model;
```{r}
set.seed(123)
plsdaTune = train(fattyAcids, oilType,
                method = "pls",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl)
plsdaTune
plot(plsdaTune)
```


store PLSDA predictions;
```{r}
testResults$plsda = predict(plsdaTune, fattyAcids)
```



Fit penalized model;
```{r}
glmnGrid = expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1),
                       .lambda = seq(.01, .2, length = 40))
set.seed(123)
glmnTune = train(fattyAcids, oilType,
                method = "glmnet",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl,
                tuneGrid = glmnGrid)
glmnTune
plot(glmnTune)
```

store glmn predictions;
```{r}
testResults$glmn = predict(glmnTune, fattyAcids)
```


fit nearest shrunken centroid model;
```{r}
nscGrid = data.frame(.threshold = 0:25)
set.seed(123)
nscTune = train(fattyAcids, oilType,
                method = "pam",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl,
                tuneGrid = nscGrid)
nscTune
plot(nscTune)
```


```{r}
testResults$nsc = predict(nscTune, fattyAcids)
```


Compute Confusion matrices for all of the models;
```{r}
confusionMatrix(testResults$lda, testResults$obs)
confusionMatrix(testResults$plsda, testResults$obs)
confusionMatrix(testResults$glmn, testResults$obs)
confusionMatrix(testResults$nsc, testResults$obs)
```


So, the best performing model here was the Nearest Shrunken Centroid. In terms of its accuracy in predicting each particular level of the response variable, we can take another look at the confusion matrix for that model;
```{r}
confusionMatrix(testResults$nsc, testResults$obs)
```

The nearest shrunken centroid model had a 5-way for most accuract predictor; C, D, E, F, and G all have 100% prediction rate. The worst accuracy rate was for Class A, which had a 97.3% accuracy rate.


#### 13.2. Use the fatty acid data from the previous exercise set (Exercise 12.2).


### (a) Use the same data splitting approach (if any) and pre-processing steps that you did in the previous chapter. Using the same classification statistic as before, build models described in this chapter for these data. Which model has the best predictive ability? How does this optimal model’s performance compare to the best linear model’s performance? Would you infer that the data have nonlinear separation boundaries based on this comparison?

So again, I am going to use centering and scaling in the train function to preprocess the data, and not split the data into training/testing sets due to the nature of the response variable and the small sample size.

The models discussed in Chapter 13 are the quadratic discrimininant analysis (QDA), the regularized discriminant analysis (RDA), the mixture discriminant analysis (MDA), naive Bayes, k-nearest neighbors, neural networks, flexible discriminant analysis, and support vector machines. I had trouble getting the QDA to run and eventually gave up on it but was able to fit all the other models discussed using the FattyAcids data.



```{r}
set.seed(123)
marsGrid <- expand.grid(.degree = 1:2, .nprune = 2:38)
FDATune = train(fattyAcids, oilType,
                method = "fda",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl,
                tuneGrid = marsGrid)
FDATune
plot(FDATune)
```

MDA model;
```{r}
set.seed(123)
MDATune = train(fattyAcids, oilType,
                method = "mda",
                preProcess = c("center", "scale"),
                tuneGrid = expand.grid(.subclasses = 1:3),
                metric = "Accuracy",
                trControl = ctrl)
plot(MDATune)
```


Naive Bayes;
```{r}
set.seed(123)
grid_nb = expand.grid(.usekernel = TRUE,
                      .fL = 2,
                      .adjust = TRUE)
NBTune = train(fattyAcids, oilType,
                method = "nb",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl,
                tuneGrid = grid_nb)
NBTune
```


Fit K-nearest neighbors model;
```{r}
set.seed(123)
KNNTune = train(fattyAcids, oilType,
                method = "knn",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl,
                tuneGrid = data.frame(.k = 1:50))
KNNTune
plot(KNNTune)
```


Fit SVM model;
```{r}
set.seed(123)
sigmaRangeReduced = sigest(as.matrix(fattyAcids))
svmRGridReduced <- expand.grid(.sigma = sigmaRangeReduced[1],.C = 2^(seq(-4, 4)))
ctrl2 = trainControl(method = "LGOCV",
                     summaryFunction = defaultSummary)

SVMTune = train(fattyAcids, oilType,
                method = "svmRadial",
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl2,
                tuneGrid = svmRGridReduced)
SVMTune
plot(SVMTune)
```

Fit Neural Network;
```{r}
set.seed(123)
nnetGrid = expand.grid(.size = 1:3,
                       .decay = c(0, .1, 1, 2))
nnetTune = train(fattyAcids, oilType,
                 method = "nnet",
                 metric = "Accuracy",
                 preProc = c("center", "scale"),
                 tuneGrid = nnetGrid,
                 trControl = ctrl,
                 trace = FALSE)
nnetTune
plot(nnetTune)
```


### (b) Which oil type does the optimal model most accurately predict? Least accurately predict?

Make predictions for each of the different models;
```{r}
testResults2 = data.frame(obs = oilType,
                          mda = predict(MDATune, fattyAcids))
testResults2$fda = predict(FDATune, fattyAcids)
testResults2$nb = predict(NBTune, fattyAcids)
testResults2$knn = predict(KNNTune, fattyAcids)
testResults2$svm = predict(SVMTune, fattyAcids)
testResults2$nnet = predict(nnetTune, fattyAcids)
```


Confusion matrices;
```{r}
confusionMatrix(testResults2$mda, testResults2$obs)
confusionMatrix(testResults2$fda, testResults2$obs)
confusionMatrix(testResults2$nb, testResults2$obs)
confusionMatrix(testResults2$knn, testResults2$obs)
confusionMatrix(testResults2$svm, testResults2$obs)
confusionMatrix(testResults2$nnet, testResults2$obs)
```


There's a couple of models here that wound up with 100% accuracy, but I don't think that that means it's a better model, that seems like there's some overfitting going on, so I think the best model here is the SVM, which had the highest non-100% accuracy rate.

```{r}
confusionMatrix(testResults2$svm, testResults2$obs)
```

Several of the oil types here have 100% prediction accuracy, and the lowest oil type prediction is for Class A.

In general, all of the non-linear models performed better than the linear models, so yes, it is reasonable to assume that there are some non-linear separation boundaries.
